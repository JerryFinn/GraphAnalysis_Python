{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx==1.11 in d:\\programs\\jerom\\anaconda3\\lib\\site-packages (1.11)\n",
      "Requirement already satisfied: decorator>=3.4.0 in d:\\programs\\jerom\\anaconda3\\lib\\site-packages (from networkx==1.11) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx==1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to install version 1.11 because on any version at 2.0 or above the call any call to `G.degree` or even `G.degree()` raised the below error:  \n",
    "`--> 346         self._succ = G._succ if hasattr(G, \"_succ\") else G._adj`  \n",
    "`AttributeError: 'Graph' object has no attribute '_adj'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Node and Edge Predictions\n",
    "\n",
    "This was an interesting assignment that was based on a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "The network also contains the node attributes `Department` and `ManagementSalary`. `ManagementSalary` indicates whether that person is receiving a management position salary.\n",
    "\n",
    "The interesting thing about predication on networks is in this class was that you did not get a dataset of features as usual, but made your own features from network metrics, whose choice all depends on what you want to predict. I tried a number of classifiers, such as random forest, gradient boosting but all gave similiar scorings, so all things being close I decided to go with a simple algorithm, logistic regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict a node attribute\n",
    "\n",
    "The goal was to predict the node attribute `ManagementSalary`, using a sklearn classifier. The dependent variable could be 1 (true) or 0 (false), and the evaluation was using Area Under the ROC Curve (AUC). So we have a straight forward binary classification problem. \n",
    "\n",
    "I create a dataframe of node features using networkx. The key assumption with this assignment is that since management is more central to a network, that is to say that they communicate with many others by the nature of their jobs, that management will be more central to the network. \n",
    "\n",
    "NetworkX has a lot of methods that provide useful metrics for this purpose. I used the number of degrees (connections), degree centrality, closeness centrality, and betweenness centrality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('email_prediction.txt')\n",
    "def node_predictions():\n",
    "    \n",
    "    # Custom code here\n",
    "    forsubmission=False\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    # Here we create the data frame where all the features will be metrics of node centrality\n",
    "    df=pd.DataFrame([G.node[i] for i in range(len(G.node))])\n",
    "    df.index=list(G.node.keys())\n",
    "    dc=nx.degree_centrality(G)\n",
    "    cc=nx.closeness_centrality(G)\n",
    "    bc=nx.betweenness_centrality(G, normalized = True)\n",
    "    df['d'] = [v for v in G.degree().values()]\n",
    "    df['dc'] = [dc[i] for i in df.index]\n",
    "    df['cc'] = [cc[i] for i in df.index]\n",
    "    df['bc'] = [bc[i] for i in df.index]\n",
    "    df=df.drop(['Department'], axis=1)\n",
    "    \n",
    "    df_val=df[df['ManagementSalary'].isnull()]\n",
    "    df2=df[~df['ManagementSalary'].isnull()]\n",
    "    X_val=df_val.drop(['ManagementSalary'], axis=1)\n",
    "\n",
    "    X=df2[['d', 'dc', 'cc', 'bc']]    \n",
    "    y=df2['ManagementSalary']\n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X,y,random_state = 0))\n",
    "\n",
    "    # Now we transform the data and get it all the same scale\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    std_X_train = scaler.transform(X_train)\n",
    "    std_X_test = scaler.transform(X_test)\n",
    "    std_X_val = scaler.transform(X_val)\n",
    "\n",
    "    # Building a model we do a grid search to find the best hyperparameters\n",
    "    lr = LogisticRegression()\n",
    "    list_grid = {'C':[0.01, 0.1, 1, 10, 100]} \n",
    "    grid_lr_acc = GridSearchCV(lr, param_grid = list_grid, scoring = 'roc_auc')\n",
    "    grid_lr_acc.fit(std_X_train, y_train)\n",
    "    if forsubmission==False:\n",
    "        print('Test set AUC: ', roc_auc_score(y_test, grid_lr_acc.predict_proba(std_X_test)[:,1]))\n",
    "\n",
    "    return_series=pd.Series(grid_lr_acc.predict_proba(std_X_val)[:,1], index=X_val.index)\n",
    "    \n",
    "    return \"In the assignment I returned the variable return_series for grading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set AUC:  0.8656184486373166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the assignment I returned the variable return_series for grading'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic grading reported these for the validation predictions:  \n",
    "`For the salary predictions your AUC 0.9211290992112909 was awarded` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge predictions\n",
    "\n",
    "The goal of the edge prediction was to predict future connections. The key assumption here is that nodes that have a lot of connections in common, will tend to form connections between themselves later.  \n",
    "  \n",
    "Once again, networkx provides a lot of useful common connections metrics that we can put into a dataframe and use as features. This model uses the basic metrics: Number of Common Neighbors, Jaccard Coefficient, Resource Allocation Index, Adamic-Adar Index, Preferential Attachment Score, Common Neighbor Score, Resource Allocation Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "def edge_predictions():\n",
    "    \n",
    "    # Custom code here\n",
    "    forsubmission=False\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    df=future_connections.copy()\n",
    "    df.head()\n",
    "    # Here we use the metrics to create a data frame of features\n",
    "    cn=[len([pair for pair in nx.common_neighbors(G,e[0],e[1])]) for e in df.index ]\n",
    "    jc=[p for u,v,p in nx.jaccard_coefficient(G, ebunch=df.index)]\n",
    "    ra=[p for u,v,p in nx.resource_allocation_index(G, ebunch=df.index)]\n",
    "    aa=[p for u,v,p in nx.adamic_adar_index(G, ebunch=df.index)]\n",
    "    pa=[p for u,v,p in nx.preferential_attachment(G, ebunch=df.index)]\n",
    "    ccn=[p for u,v,p in nx.cn_soundarajan_hopcroft(G,ebunch=df.index,community='Department')]\n",
    "    cra=[p for u,v,p in nx.ra_index_soundarajan_hopcroft(G,ebunch=df.index,community='Department')]\n",
    "\n",
    "    df['cn']=cn\n",
    "    df['jc']=jc\n",
    "    df['ra']=ra\n",
    "    df['aa']=aa\n",
    "    df['pa']=pa\n",
    "    df['ccn']=ccn\n",
    "    df['cra']=cra\n",
    "\n",
    "    df_val=df[df['Future Connection'].isnull()]\n",
    "    df2=df[~df['Future Connection'].isnull()]\n",
    "    X_val=df_val.drop(['Future Connection'], axis=1)\n",
    "\n",
    "    X=df2[['cn', 'jc', 'ra', 'aa', 'pa', 'ccn', 'cra']]    \n",
    "    y=df2['Future Connection']\n",
    "    X_train, X_test, y_train, y_test = (train_test_split(X,y,random_state = 0))\n",
    "\n",
    "    # Trans for the data so all the features are on the same scale\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    std_X_train = scaler.transform(X_train)\n",
    "    std_X_test = scaler.transform(X_test)\n",
    "    std_X_val = scaler.transform(X_val)\n",
    "\n",
    "    # we'll use a grid search so our model has the best hyperparameters\n",
    "    lr = LogisticRegression()\n",
    "    list_grid = {'C':[0.01, 0.1, 1, 10, 100]} \n",
    "    grid_lr_acc = GridSearchCV(lr, param_grid = list_grid, scoring = 'roc_auc')\n",
    "    grid_lr_acc.fit(std_X_train, y_train)\n",
    "    if forsubmission==False:\n",
    "        print('Test set AUC: ', roc_auc_score(y_test, grid_lr_acc.predict_proba(std_X_test)[:,1]))\n",
    "\n",
    "    return_series=pd.Series(grid_lr_acc.predict_proba(std_X_val)[:,1], index=X_val.index)\n",
    "    return \"In the assignment we returned the variable return_series for automatic grading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set AUC:  0.9126945905047377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the assignment we returned the variable return_series for automatic grading'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "The automatic grading reported these for the validation predictions:  \n",
    "`For the new connections predictions your AUC 0.9136392864156448`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "So when everything is said and done I did better on the validation data then I did on the train/test split. It really was the feature creation that made a difference as most algorithms came up with very close scores. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
